{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/unitary_detoxify/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import load_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, embeddings, metadata = load_embeddings('/home/ubuntu/dev/detoxify/jigsaw-toxic-comment-classification-challenge/data/embeddings_t5-large_test_This_text_is_about_{}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv('/home/ubuntu/dev/detoxify/jigsaw-toxic-comment-classification-challenge/data/test_labels.csv', dtype={\"id\": \"string\"})\n",
    "classes = list(labels.columns)\n",
    "classes.remove(\"id\")\n",
    "y = labels[classes].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (y != -1).any(axis=1)\n",
    "y_m = y[mask, :]\n",
    "embeddings_m = embeddings[mask, :]\n",
    "y_m.shape, embeddings_m.shape\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings_m, y_m, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.90765101\n",
      "Iteration 2, loss = 0.50535811\n",
      "Iteration 3, loss = 0.46260219\n",
      "Iteration 4, loss = 0.44124577\n",
      "Iteration 5, loss = 0.42704618\n",
      "Iteration 6, loss = 0.41552710\n",
      "Iteration 7, loss = 0.40524844\n",
      "Iteration 8, loss = 0.39705656\n",
      "Iteration 9, loss = 0.38864598\n",
      "Iteration 10, loss = 0.38183094\n",
      "Iteration 11, loss = 0.37542866\n",
      "Iteration 12, loss = 0.36787716\n",
      "Iteration 13, loss = 0.36130294\n",
      "Iteration 14, loss = 0.35559879\n",
      "Iteration 15, loss = 0.35004788\n",
      "Iteration 16, loss = 0.34373162\n",
      "Iteration 17, loss = 0.33862601\n",
      "Iteration 18, loss = 0.33315929\n",
      "Iteration 19, loss = 0.32730203\n",
      "Iteration 20, loss = 0.32269194\n",
      "Iteration 21, loss = 0.31702285\n",
      "Iteration 22, loss = 0.31090028\n",
      "Iteration 23, loss = 0.30542578\n",
      "Iteration 24, loss = 0.30040920\n",
      "Iteration 25, loss = 0.29530497\n",
      "Iteration 26, loss = 0.29026949\n",
      "Iteration 27, loss = 0.28477819\n",
      "Iteration 28, loss = 0.27959087\n",
      "Iteration 29, loss = 0.27448070\n",
      "Iteration 30, loss = 0.27000308\n",
      "Iteration 31, loss = 0.26518120\n",
      "Iteration 32, loss = 0.26040492\n",
      "Iteration 33, loss = 0.25629692\n",
      "Iteration 34, loss = 0.25245743\n",
      "Iteration 35, loss = 0.24730421\n",
      "Iteration 36, loss = 0.24252999\n",
      "Iteration 37, loss = 0.23944714\n",
      "Iteration 38, loss = 0.23494634\n",
      "Iteration 39, loss = 0.23051767\n",
      "Iteration 40, loss = 0.22680040\n",
      "Iteration 41, loss = 0.22225255\n",
      "Iteration 42, loss = 0.21757542\n",
      "Iteration 43, loss = 0.21510423\n",
      "Iteration 44, loss = 0.21139703\n",
      "Iteration 45, loss = 0.20700423\n",
      "Iteration 46, loss = 0.20380308\n",
      "Iteration 47, loss = 0.19962295\n",
      "Iteration 48, loss = 0.19709434\n",
      "Iteration 49, loss = 0.19263468\n",
      "Iteration 50, loss = 0.18963373\n",
      "Iteration 51, loss = 0.18706222\n",
      "Iteration 52, loss = 0.18283063\n",
      "Iteration 53, loss = 0.18011892\n",
      "Iteration 54, loss = 0.17601120\n",
      "Iteration 55, loss = 0.17263834\n",
      "Iteration 56, loss = 0.17025319\n",
      "Iteration 57, loss = 0.16695355\n",
      "Iteration 58, loss = 0.16407621\n",
      "Iteration 59, loss = 0.16115758\n",
      "Iteration 60, loss = 0.15763415\n",
      "Iteration 61, loss = 0.15502055\n",
      "Iteration 62, loss = 0.15148151\n",
      "Iteration 63, loss = 0.14939427\n",
      "Iteration 64, loss = 0.14580604\n",
      "Iteration 65, loss = 0.14342071\n",
      "Iteration 66, loss = 0.14023536\n",
      "Iteration 67, loss = 0.13729141\n",
      "Iteration 68, loss = 0.13572438\n",
      "Iteration 69, loss = 0.13386913\n",
      "Iteration 70, loss = 0.13027002\n",
      "Iteration 71, loss = 0.12699818\n",
      "Iteration 72, loss = 0.12477218\n",
      "Iteration 73, loss = 0.12393631\n",
      "Iteration 74, loss = 0.11988310\n",
      "Iteration 75, loss = 0.11770488\n",
      "Iteration 76, loss = 0.11512595\n",
      "Iteration 77, loss = 0.11376940\n",
      "Iteration 78, loss = 0.11077663\n",
      "Iteration 79, loss = 0.10929288\n",
      "Iteration 80, loss = 0.10692470\n",
      "Iteration 81, loss = 0.10437366\n",
      "Iteration 82, loss = 0.10172950\n",
      "Iteration 83, loss = 0.10051171\n",
      "Iteration 84, loss = 0.09855650\n",
      "Iteration 85, loss = 0.09600820\n",
      "Iteration 86, loss = 0.09397948\n",
      "Iteration 87, loss = 0.09238527\n",
      "Iteration 88, loss = 0.08956346\n",
      "Iteration 89, loss = 0.08841752\n",
      "Iteration 90, loss = 0.08618849\n",
      "Iteration 91, loss = 0.08444541\n",
      "Iteration 92, loss = 0.08293130\n",
      "Iteration 93, loss = 0.08089824\n",
      "Iteration 94, loss = 0.07991101\n",
      "Iteration 95, loss = 0.07843680\n",
      "Iteration 96, loss = 0.07623303\n",
      "Iteration 97, loss = 0.07431181\n",
      "Iteration 98, loss = 0.07254902\n",
      "Iteration 99, loss = 0.07121127\n",
      "Iteration 100, loss = 0.06953430\n",
      "Iteration 101, loss = 0.06817999\n",
      "Iteration 102, loss = 0.06631737\n",
      "Iteration 103, loss = 0.06597461\n",
      "Iteration 104, loss = 0.06401843\n",
      "Iteration 105, loss = 0.06259081\n",
      "Iteration 106, loss = 0.06100168\n",
      "Iteration 107, loss = 0.05925153\n",
      "Iteration 108, loss = 0.05798465\n",
      "Iteration 109, loss = 0.05736059\n",
      "Iteration 110, loss = 0.05550413\n",
      "Iteration 111, loss = 0.05545173\n",
      "Iteration 112, loss = 0.05343360\n",
      "Iteration 113, loss = 0.05217004\n",
      "Iteration 114, loss = 0.05119623\n",
      "Iteration 115, loss = 0.04976646\n",
      "Iteration 116, loss = 0.04933736\n",
      "Iteration 117, loss = 0.04818417\n",
      "Iteration 118, loss = 0.04767035\n",
      "Iteration 119, loss = 0.04582912\n",
      "Iteration 120, loss = 0.04457877\n",
      "Iteration 121, loss = 0.04339399\n",
      "Iteration 122, loss = 0.04340752\n",
      "Iteration 123, loss = 0.04244260\n",
      "Iteration 124, loss = 0.04101428\n",
      "Iteration 125, loss = 0.03977010\n",
      "Iteration 126, loss = 0.03949669\n",
      "Iteration 127, loss = 0.03829684\n",
      "Iteration 128, loss = 0.03726278\n",
      "Iteration 129, loss = 0.03659877\n",
      "Iteration 130, loss = 0.03591687\n",
      "Iteration 131, loss = 0.03523127\n",
      "Iteration 132, loss = 0.03506831\n",
      "Iteration 133, loss = 0.03448844\n",
      "Iteration 134, loss = 0.03430347\n",
      "Iteration 135, loss = 0.03215096\n",
      "Iteration 136, loss = 0.03127407\n",
      "Iteration 137, loss = 0.03079268\n",
      "Iteration 138, loss = 0.03031613\n",
      "Iteration 139, loss = 0.02971181\n",
      "Iteration 140, loss = 0.02891832\n",
      "Iteration 141, loss = 0.02914567\n",
      "Iteration 142, loss = 0.02809224\n",
      "Iteration 143, loss = 0.02726514\n",
      "Iteration 144, loss = 0.02726774\n",
      "Iteration 145, loss = 0.02620126\n",
      "Iteration 146, loss = 0.02564779\n",
      "Iteration 147, loss = 0.02509350\n",
      "Iteration 148, loss = 0.02510704\n",
      "Iteration 149, loss = 0.02487474\n",
      "Iteration 150, loss = 0.02516661\n",
      "Iteration 151, loss = 0.02366782\n",
      "Iteration 152, loss = 0.02311330\n",
      "Iteration 153, loss = 0.02257868\n",
      "Iteration 154, loss = 0.02229787\n",
      "Iteration 155, loss = 0.02229125\n",
      "Iteration 156, loss = 0.02226523\n",
      "Iteration 157, loss = 0.02095177\n",
      "Iteration 158, loss = 0.02080690\n",
      "Iteration 159, loss = 0.02076249\n",
      "Iteration 160, loss = 0.02006647\n",
      "Iteration 161, loss = 0.01981157\n",
      "Iteration 162, loss = 0.02070016\n",
      "Iteration 163, loss = 0.02024509\n",
      "Iteration 164, loss = 0.01911902\n",
      "Iteration 165, loss = 0.01828936\n",
      "Iteration 166, loss = 0.01809044\n",
      "Iteration 167, loss = 0.01709871\n",
      "Iteration 168, loss = 0.01775914\n",
      "Iteration 169, loss = 0.02048245\n",
      "Iteration 170, loss = 0.01987930\n",
      "Iteration 171, loss = 0.01747734\n",
      "Iteration 172, loss = 0.01725711\n",
      "Iteration 173, loss = 0.01632233\n",
      "Iteration 174, loss = 0.01582176\n",
      "Iteration 175, loss = 0.01580884\n",
      "Iteration 176, loss = 0.01560662\n",
      "Iteration 177, loss = 0.01572742\n",
      "Iteration 178, loss = 0.01545073\n",
      "Iteration 179, loss = 0.01532703\n",
      "Iteration 180, loss = 0.01588439\n",
      "Iteration 181, loss = 0.01507149\n",
      "Iteration 182, loss = 0.01578620\n",
      "Iteration 183, loss = 0.02416073\n",
      "Iteration 184, loss = 0.01773350\n",
      "Iteration 185, loss = 0.01490266\n",
      "Iteration 186, loss = 0.01415616\n",
      "Iteration 187, loss = 0.01407716\n",
      "Iteration 188, loss = 0.01381134\n",
      "Iteration 189, loss = 0.01386173\n",
      "Iteration 190, loss = 0.01334724\n",
      "Iteration 191, loss = 0.01402012\n",
      "Iteration 192, loss = 0.01522902\n",
      "Iteration 193, loss = 0.01457162\n",
      "Iteration 194, loss = 0.01384007\n",
      "Iteration 195, loss = 0.01410230\n",
      "Iteration 196, loss = 0.01439842\n",
      "Iteration 197, loss = 0.01455275\n",
      "Iteration 198, loss = 0.01682443\n",
      "Iteration 199, loss = 0.01453144\n",
      "Iteration 200, loss = 0.01294311\n",
      "Iteration 201, loss = 0.01254284\n",
      "Iteration 202, loss = 0.01258122\n",
      "Iteration 203, loss = 0.01266075\n",
      "Iteration 204, loss = 0.01249376\n",
      "Iteration 205, loss = 0.01249060\n",
      "Iteration 206, loss = 0.01248614\n",
      "Iteration 207, loss = 0.01290219\n",
      "Iteration 208, loss = 0.01280513\n",
      "Iteration 209, loss = 0.01240924\n",
      "Iteration 210, loss = 0.01843584\n",
      "Iteration 211, loss = 0.01561294\n",
      "Iteration 212, loss = 0.01234253\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=1, max_iter=300, verbose=True).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.2514755e-15, 1.4337943e-31, 5.1483272e-15, 2.2868316e-23,\n",
       "         3.3044348e-10, 3.7310001e-24]], dtype=float32),\n",
       " array([[0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0]]),\n",
       " 0.8835261019068459)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test[:1]), clf.predict(X_test[:5, :]), clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_eval.eval_predictions import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = clf.predict_proba(embeddings_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc_scores': [0.9814988952110456,\n",
       "  0.9924035682310701,\n",
       "  0.98216076674368,\n",
       "  0.9886367259595935,\n",
       "  0.9851924364443544,\n",
       "  0.9876299666789446],\n",
       " 'mean_auc': 0.9862537265447814}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(scores, y_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('unitary_detoxify')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d715a8e0c373335788d71af889f0d8a209e19c45567465c102df97a24f52ada6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
