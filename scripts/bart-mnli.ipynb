{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose sequence as a NLI premise and label as a hypothesis\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli')\n",
    "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sequence = \"one day I will see the world\"\n",
    "batch_sentences = [\n",
    "    \"one day I will see the world\",\n",
    "    \"Don't think he knows about second breakfast, Pip.\",\n",
    "    \"What about elevensies?\"\n",
    "]\n",
    "labels = ['travel', 'cooking', 'dancing']\n",
    "premise = sequence\n",
    "hypothesis = f'This example is {labels[0]}'\n",
    "hypotheses = [f'This example is {label}.' for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    0,  1264,   183,    38,    40,   192,     5,   232,     2,     1,\n",
      "             1,     1,     1],\n",
      "        [    0,  6766,    75,   206,    37,  2215,    59,   200,  7080,     6,\n",
      "         30533,     4,     2],\n",
      "        [    0,  2264,    59, 19353,    29,   918,   116,     2,     1,     1,\n",
      "             1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])}\n",
      "Input IDs: tensor([3, 3])\n",
      "Logits: tensor([[-2.6491,  3.7369, -1.7229],\n",
      "        [ 0.1108,  2.3191, -2.5804],\n",
      "        [ 0.6952, -0.1324, -0.9485]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(batch_sentences, padding=True, return_tensors=\"pt\") # truncation=True\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "input_ids = torch.tensor(ids)\n",
    "print(tokens)\n",
    "print(\"Input IDs:\", input_ids)\n",
    "\n",
    "output = nli_model(**tokens)\n",
    "print(\"Logits:\", output.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits: tensor([[-2.6491,  3.7369, -1.7229],\n",
      "        [ 0.1108,  2.3191, -2.5804],\n",
      "        [ 0.6952, -0.1324, -0.9485]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pairs = [(seq, hypo) for seq in batch_sentences for hypo in hypotheses]\n",
    "x = tokenizer.batch_encode_plus(pairs, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "output = nli_model(**tokens)\n",
    "print(\"Logits:\", output.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# run through model pre-trained on MNLI\n",
    "x = tokenizer.encode(premise, hypothesis, return_tensors='pt',\n",
    "                     truncation_strategy='only_first')\n",
    "logits = nli_model(x)\n",
    "\n",
    "# we throw away \"neutral\" (dim 1) and take the probability of\n",
    "# \"entailment\" (2) as the probability of the label being true \n",
    "entail_contradiction_logits = logits[:,[0,2]]\n",
    "probs = entail_contradiction_logits.softmax(dim=1)\n",
    "prob_label_is_true = probs[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0, 1264,  183,   38,   40,  192,    5,  232,    2,    2,  713, 1246,\n",
       "           16, 1504,    4,    2]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('unitary_detoxify')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d715a8e0c373335788d71af889f0d8a209e19c45567465c102df97a24f52ada6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
